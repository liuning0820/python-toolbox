# rag_chat.py
import chromadb
from ollama import embed, chat

DB_DIR = "rag_vectors_db"

client = chromadb.PersistentClient(path=DB_DIR)
collection = client.get_collection("notes")

def rag_query(query: str):
    query_emb = embed(model="bge-m3", input=query).embeddings[0]
    results = collection.query(query_embeddings=[query_emb], n_results=3)

    context = "\n\n".join(results["documents"][0])
    prompt = f"""ä½ æ˜¯ä¸€ä¸ªæœ¬åœ°çŸ¥è¯†åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯æˆ‘çš„ç¬”è®°ç‰‡æ®µï¼š
{context}

åŸºäºè¿™äº›å†…å®¹ï¼Œå›ç­”é—®é¢˜ï¼š{query}
"""

    response = chat(model="qwen2.5-coder:1.5b", messages=[{"role":"user","content":prompt}])
    return response["message"]["content"]

if __name__ == "__main__":
    while True:
        q = input("\nâ“ é—®é¢˜: ")
        if q.strip().lower() in ["exit", "quit"]:
            break
        print("\nğŸ’¡ å›ç­”:\n", rag_query(q))
